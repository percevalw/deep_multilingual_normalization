# Pipeline
[nlp]
lang = "eds"
pipeline = ["linker"]
components = ${components}
tokenizer = {"@tokenizers": "eds.tokenizer"}

[components.linker]
@factory = "eds.span_linker"
rescale = 20
metric = "cosine"
threshold = 0.
reference_mode = "concept"
probability_mode = "sigmoid"
init_weights = true

[components.linker.embedding]
@factory = "eds.span_pooler"
span_getter = "entities"
pooling_mode = "mean"
hidden_size = 350

[components.linker.embedding.embedding]
@factory = "eds.transformer"
span_getter = "entities"
model = "bert-base-multilingual-uncased"

[val_docs]
@readers = "standoff"
path = "data/dataset/train/"
span_setter = "entities"
notes_as_span_attribute = "cui"
split_fragments = false

# Scripts
[pretrain]
nlp = ${nlp}
dropout = 0.2
seed = 42
max_steps = 20000
transformer_lr = 5e-5
task_lr = 1e-4
batch_size = 512
max_grad_norm = 10.0
warmup_rate = 0.1
val_docs = ${val_docs}
umls_path = "data/umls/2014AB/"
query = "GRP IN ('ANAT','CHEM','DEVI','DISO','GEOG','LIVB','OBJC','PHEN','PHYS','PROC') and LAT in ('FRE', 'ENG', 'ITA', 'SPA')"
cui_query = "LAT = 'FRE'"
output_dir = "artifacts/model-inter"
debug = false

[train_classifier]
nlp = "artifacts/model-inter"
seed = 42
task_lr = 1e-4
batch_size = 512
warmup_rate = 0
training_top_k = 200
val_docs = ${val_docs}
umls_path = "data/umls/2014AB/"
query = "GRP IN ('ANAT','CHEM','DEVI','DISO','GEOG','LIVB','OBJC','PHEN','PHYS','PROC') and (LAT in ('FRE') or (LAT in ('ENG', 'ITA', 'SPA') AND SAB IN ('CHV', 'SNOMEDCT_US', 'MTH', 'NCI', 'MSH', 'MSHITA', 'MSHSPA', 'SCTSPA')))"
cui_query = "LAT = 'FRE' or LAT = 'ENG'"
output_dir = "artifacts/model-last"
max_steps = 10000
debug = false

[evaluate]
data = ${val_docs}
